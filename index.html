<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-CSCI-736-Neural-Network" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/10/CSCI-736-Neural-Network/" class="article-date">
  <time class="dt-published" datetime="2021-03-10T06:39:36.000Z" itemprop="datePublished">2021-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/10/CSCI-736-Neural-Network/">CSCI 736 Neural Network</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="csci-736-neural-network">CSCI 736 Neural Network</h1>
<p>[toc]</p>
<h1 id="paper-time-line">Paper Time Line</h1>
<p>Write 1 and 5</p>
<table>
<thead>
<tr class="header">
<th>Paper Content</th>
<th>Time Schedule</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="CSCI-736-Neural-Network.assets/5871614469525_.pic_hd.jpg" alt="5871614469525_.pic_hd" style="zoom: 25%;" /></td>
<td><img src="CSCI-736-Neural-Network.assets/5991614469878_.pic_hd.jpg" alt="5991614469878_.pic_hd" style="zoom:25%;" /></td>
</tr>
</tbody>
</table>
<h2 id="paper-math-equation">Paper Math Equation</h2>
$$ p_{end,j}= , j {n+1, n+2, n+3 2 n}\
<span class="math display">\[\begin{aligned}

&amp;input=[q_{1},q_{2},q_{3},\cdots, q_{N}],[d_{1}, d_{2}, d_{3}, \cdots,d_{M}], \text{(N,M : the number of tokens)}\\
&amp;outputs=[index\ \ of\ \ max(p_{i}),index\ \ of\ \  max(p_{j}))]\\

&amp;p_{start}=\frac{e^{z_i}}{\sum\limits_{i=1}^{n}e^{z_i}}, i \in \{1,2,3\cdots, M\}\\

&amp;p_{end}=\frac{e^{z_{j}}}{\sum\limits_{j=1}^{n} e^{z_{j}}},\\ &amp;j \in\{1, 2, 3 \ldots M\} \\
 
&amp;loss=-log(p_{start,I})-log(p_{end,J})\\
&amp;\text{the correct start and end position are }\\&amp;
I \in\{1,2,3,4 \ldots \mathrm{n},J \in\{1,2,3,4 \ldots \mathrm{n}\}


\end{aligned}\]</span>
<p>$$</p>
<h2 id="learning-resource">Learning Resource</h2>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1JE411g7XF?from=search&amp;seid=13732374700367344665">李宏毅</a></p>
<h1 id="文章理解">文章理解</h1>
<p>embedding(八种常用的embedding)-&gt;rnn-&gt;lstm&amp;gru-&gt;attention-&gt;seq2seq-&gt;self-attention-&gt;transformer-&gt;bert</p>
<p><strong>embedding</strong></p>
<p><strong>RNN</strong></p>
<p><img src="CSCI-736-Neural-Network.assets/v2-3884f344d71e92d70ec3c44d2795141f_1440w-20210308084120851.jpg" alt="v2-3884f344d71e92d70ec3c44d2795141f_1440w" style="zoom:25%;" /></p>
<figure>
<img src="CSCI-736-Neural-Network.assets/v2-b0175ebd3419f9a11a3d0d8b00e28675_1440w-20210308084146454.jpg" alt="" /><figcaption>v2-b0175ebd3419f9a11a3d0d8b00e28675_1440w</figcaption>
</figure>
<figure>
<img src="CSCI-736-Neural-Network.assets/v2-9e50e23bd3dff0d91b0198d0e6b6429a_1440w-20210308084225295.jpg" alt="" /><figcaption>v2-9e50e23bd3dff0d91b0198d0e6b6429a_1440w</figcaption>
</figure>
<h3 id="lstm"><strong>LSTM</strong></h3>
<h3 id="gru"><strong>GRU</strong></h3>
<h3 id="attention"><strong>attention</strong></h3>
<p>参数少, 速度快, 效果好</p>
<p><a target="_blank" rel="noopener" href="https://shangzhih.github.io/jian-shu-attentionji-zhi.html">优质教程</a></p>
<h3 id="encoderdecoder"><strong>Encoder&amp;Decoder</strong></h3>
<p>一类算法的统称</p>
<p>这类算法的统称:</p>
<ol type="1">
<li>无论输入和输出的长度是什么, 中间的 向量c 长度固定</li>
<li>根据不同任务可以选择不同的编码器和解码器</li>
</ol>
<p>缺点: 当输入信息太长时，会丢失掉一些信息.</p>
<h3 id="seq2seq-in-encoderdeconder"><strong>seq2seq <span class="math inline">\(\in Encoder\&amp;Deconder\)</span></strong></h3>
<p>一类算法的统称</p>
<p>这类算法的统称: 满足输入序列, 输出序列的目的</p>
<h3 id="self-attention"><strong>self-attention</strong></h3>
<h3 id="transformer"><strong>transformer</strong></h3>
<h3 id="bert"><strong>bert</strong></h3>
<p>linear classifier: two vector</p>
<p>each vector dot product the embedding, then apply softmax, find maximum to get index</p>
<h3 id="deep-auto-encoder"><strong>Deep Auto-encoder</strong></h3>
<p>Paper:<a href="Papers/Deep%20Auto-Encoder%20Neural%20Networks%20in%20Reinforcement%20Learning.pdf">Deep Auto-Encoder Neural Networks in Reinforcement Learning</a></p>
<p>PPT:<a href="李宏毅PPT/Unsupervised%20Learning-Auto-encoder.pptx">Unsupervised Learning-Auto-encoder</a></p>
<p><img src="CSCI-736-Neural-Network.assets/image-20210309201413384.png" alt="image-20210309201413384" style="zoom:50%;" /></p>
<p>Stating from PCA</p>
<p><img src="CSCI-736-Neural-Network.assets/image-20210309202019613.png" alt="image-20210309202019613" style="zoom:50%;" /></p>
<p>可以把PCA的前半部分视为encode, 后半部分decode</p>
<p><strong>重要特性:增强robust</strong></p>
<p><img src="CSCI-736-Neural-Network.assets/image-20210309210413591.png" alt="image-20210309210413591" style="zoom:50%;" /></p>
<p>对CNN建立decoder, decoding的过程实际还是在卷积</p>
<p><img src="CSCI-736-Neural-Network.assets/image-20210309220008147.png" alt="image-20210309220008147" style="zoom:50%;" /></p>
<table>
<thead>
<tr class="header">
<th>图一</th>
<th>图二</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="CSCI-736-Neural-Network.assets/image-20210309215606227.png" alt="image-20210309215606227" style="zoom:50%;" /></td>
<td><img src="CSCI-736-Neural-Network.assets/image-20210309215051149.png" alt="image-20210309215051149" style="zoom:50%;" /></td>
</tr>
</tbody>
</table>
<p>这一页ppt只是简单讲了下如何世纪一个discrminator 来保证auto-encoder decoder效果好(decoder尽可能把vector还原为原始图像)</p>
<p>所以这启发我们: 我们需要一个足够好的能够衡量encoder与decoder的discriminator/classifier来监督encoder与decoder的训练与一个足够好的encoder来保证vector与原始图像能尽量一一对应(每个原始数据尽量能有独一无二的embedding)</p>
<p>参考文章: Deep InfoMax (DIM)</p>
<p>若训练集是sequential, skip thought</p>
<h2 id="skip-thought-quick-thought-httpsarxiv.orgpdf1803.02893.pdf">skip thought-&gt;quick thought https://arxiv.org/pdf/1803.02893.pdf</h2>
<p>quick thought 只认encoder不管decoder, 每一个句子的ebedding跟他下一个句子的embedding越接近越好, 跟随机的句子的emberdding越不同越好</p>
<p>quick设计的classifier:输入句子A应用encoder产生的embedding, 句子A的下一句应用encoder产生的embedding, 一对随机句子应用encoder产生的embedding, classifier需要能够认为句子A的下一句巨句子A的相似度最高</p>
<p>这样的classifier与产生这个embedding的encoder同时训练</p>
<h2 id="feature-disentangle">Feature Disentangle</h2>
<p><img src="CSCI-736-Neural-Network.assets/image-20210309222925667.png" alt="image-20210309222925667" style="zoom:50%;" /></p>
<table>
<thead>
<tr class="header">
<th>-</th>
<th>-</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="CSCI-736-Neural-Network.assets/image-20210309223058277.png" alt="image-20210309223058277" style="zoom:50%;" /></td>
<td><img src="CSCI-736-Neural-Network.assets/image-20210310001401154.png" alt="image-20210310001401154" style="zoom:50%;" /></td>
</tr>
</tbody>
</table>
<p>假设encoder返回的前100个embedding 放入speaker classifier中进行训练 ,直到speaker classifier无法区分出那种音色, 这时候就认为前100已经没有了音色信息, 音色信息跑到了后100个中</p>
<p>Instance normalization:一种特逼得layer, 可以抹掉不想要的信息</p>
<p>比如全部抹掉音色信息 ,那么剩下的就是纯正的语音信息, 具体方案依赖Gan实现</p>
<h2 id="vector-quantized-variational-auto-encoder-vqvae">Vector Quantized Variational Auto-encoder (VQVAE)</h2>
<table>
<thead>
<tr class="header">
<th>-</th>
<th>-</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="CSCI-736-Neural-Network.assets/image-20210310001750278.png" alt="image-20210310001750278" /></td>
<td><img src="CSCI-736-Neural-Network.assets/image-20210309225757217.png" alt="image-20210309225757217" style="zoom:100%;" /></td>
</tr>
</tbody>
</table>
<p>返回的vector对其内容做one-hot(最大的变1其余0)转换或者binary转换(设定threshold, 大于的变为1其余0), 推荐binary, 这样可以意外的发现训练集中原本不存在的cluster</p>
<p>假设codebook中只有5个vector, 则encoding返回的vector与这五个做相似度比较, 与codebook中哪一个相似就把codebook中的哪个返回给decoder</p>
<h2 id="seq2seq2seq">seq2seq2seq</h2>
<figure>
<img src="CSCI-736-Neural-Network.assets/image-20210310002011618.png" alt="" /><figcaption>image-20210310002011618</figcaption>
</figure>
<h2 id="presentation">Presentation</h2>
<ol type="1">
<li><p>自我介绍, 标题页</p></li>
<li><p>第二页!!</p>
<p>the thoughts of our algorithm is that you input the question and document and it return subspan of the documents as the answer.</p>
<p>Here is an example of the model</p></li>
<li><p>As we choose bert as baseline, we inputs tokens and bert return the answer's start and end index.</p>
<p>So let's assume that our question has n tokens and documents have m tokens, we inputs their concatenation into bert.</p>
<p>最后一页!!!</p>
<p>The bert will return vector <span class="math inline">\(\C\)</span> which has the same dismension as inputs but we only need the document part, because the answer is just the sub span of input document.</p>
<p>As we need to find the start and end index, we prepare two linear classifiers</p>
<p>We use them take dot product with <span class="math inline">\(\C\)</span>'s document part and apply softmax to get p{start,i }and p{end,j} probabilty distribution</p>
<p>Assume the correct start and end index named "I" and "J", then we could get the p_I from p_startdistri, p_J from p_end_j distri ,then the loss fucntion for this sample is <span class="math display">\[
\text{should have correspond equation}
\]</span> Next, we apply backpropagation.</p>
<p>we reapeat these processes until finish all training part.</p>
<p>Beyond the basic QA system, our goal is to make it robust on unseen domain, to achieve such goal,we will try some existing strategies which will be discussed in related work and see if we can make any improvements.</p></li>
</ol>
<p>CLS: the key word of the classifier</p>
<p>SEP: separate question tokens and document tokens</p>
<p>问题集</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/03/10/CSCI-736-Neural-Network/" data-id="ckm32wcx90000zw9qflphb6i0" data-title="CSCI 736 Neural Network" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/10/hello-world/" class="article-date">
  <time class="dt-published" datetime="2021-03-10T05:45:12.247Z" itemprop="datePublished">2021-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/10/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2>
<h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/03/10/hello-world/" data-id="ckm32wcxg0001zw9qch7k5o2e" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/03/10/CSCI-736-Neural-Network/">CSCI 736 Neural Network</a>
          </li>
        
          <li>
            <a href="/2021/03/10/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>